{"cells":[{"cell_type":"markdown","metadata":{"id":"7I-2no9zuInd"},"source":["# Breast Cancer Detection using PyTorch (Logistic Regression)\n","\n","This notebook implements a **Binary Classification Model** using **Logistic Regression** built from scratch with **PyTorch**.\n","\n","### Complete Pipeline:\n","1. **Import Libraries**: Load necessary Python libraries.\n","2. **Load Dataset**: Fetch the Breast Cancer dataset from a remote URL.\n","3. **Data Cleaning**: Remove unused columns.\n","4. **Train-Test Split**: Divide data into training and testing sets.\n","5. **Feature Scaling**: Normalize features using StandardScaler.\n","6. **Label Encoding**: Convert categorical labels ('M', 'B') into numerical values (1, 0).\n","7. **Convert to PyTorch Tensors**: Prepare data for PyTorch.\n","8. **Define Neural Network Model**: Create a Logistic Regression model class.\n","9. **Define Loss Function**: Implement Binary Cross Entropy Loss manually.\n","10. **Training Loop**: Train the model using Gradient Descent.\n","11. **Evaluation**: Test the model's accuracy on unseen data."]},{"cell_type":"markdown","metadata":{"id":"NPc5blfVuIng"},"source":["## 1Ô∏è‚É£ Import Required Libraries\n","\n","We will import:\n","- `numpy` and `pandas` for data manipulation.\n","- `torch` for building the neural network.\n","- `sklearn` for data preprocessing and splitting."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKaQ9pg5uIng","executionInfo":{"status":"ok","timestamp":1770897867166,"user_tz":-330,"elapsed":8469,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}},"outputId":"a64ac4d9-b8c8-4fbe-e2ce-2550d9b9259f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Libraries imported successfully!\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import LabelEncoder\n","\n","print(\"Libraries imported successfully!\")"]},{"cell_type":"markdown","metadata":{"id":"tErzS4e-uIni"},"source":["## 2Ô∏è‚É£ Load Dataset\n","\n","We load the dataset directly from the raw GitHub URL.\n","The dataset contains features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"id":"NjDOufYeuInj","executionInfo":{"status":"ok","timestamp":1770897879109,"user_tz":-330,"elapsed":53,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}},"outputId":"34128452-c571-46c3-a76c-b1d03f205a31"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Shape: (569, 33)\n"]},{"output_type":"execute_result","data":{"text/plain":["         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n","0    842302         M        17.99         10.38          122.80     1001.0   \n","1    842517         M        20.57         17.77          132.90     1326.0   \n","2  84300903         M        19.69         21.25          130.00     1203.0   \n","3  84348301         M        11.42         20.38           77.58      386.1   \n","4  84358402         M        20.29         14.34          135.10     1297.0   \n","\n","   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n","0          0.11840           0.27760          0.3001              0.14710   \n","1          0.08474           0.07864          0.0869              0.07017   \n","2          0.10960           0.15990          0.1974              0.12790   \n","3          0.14250           0.28390          0.2414              0.10520   \n","4          0.10030           0.13280          0.1980              0.10430   \n","\n","   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n","0  ...          17.33           184.60      2019.0            0.1622   \n","1  ...          23.41           158.80      1956.0            0.1238   \n","2  ...          25.53           152.50      1709.0            0.1444   \n","3  ...          26.50            98.87       567.7            0.2098   \n","4  ...          16.67           152.20      1575.0            0.1374   \n","\n","   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n","0             0.6656           0.7119                0.2654          0.4601   \n","1             0.1866           0.2416                0.1860          0.2750   \n","2             0.4245           0.4504                0.2430          0.3613   \n","3             0.8663           0.6869                0.2575          0.6638   \n","4             0.2050           0.4000                0.1625          0.2364   \n","\n","   fractal_dimension_worst  Unnamed: 32  \n","0                  0.11890          NaN  \n","1                  0.08902          NaN  \n","2                  0.08758          NaN  \n","3                  0.17300          NaN  \n","4                  0.07678          NaN  \n","\n","[5 rows x 33 columns]"],"text/html":["\n","  <div id=\"df-32a4e997-2942-4d84-a907-7b2a970a34b0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>diagnosis</th>\n","      <th>radius_mean</th>\n","      <th>texture_mean</th>\n","      <th>perimeter_mean</th>\n","      <th>area_mean</th>\n","      <th>smoothness_mean</th>\n","      <th>compactness_mean</th>\n","      <th>concavity_mean</th>\n","      <th>concave points_mean</th>\n","      <th>...</th>\n","      <th>texture_worst</th>\n","      <th>perimeter_worst</th>\n","      <th>area_worst</th>\n","      <th>smoothness_worst</th>\n","      <th>compactness_worst</th>\n","      <th>concavity_worst</th>\n","      <th>concave points_worst</th>\n","      <th>symmetry_worst</th>\n","      <th>fractal_dimension_worst</th>\n","      <th>Unnamed: 32</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>842302</td>\n","      <td>M</td>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.3001</td>\n","      <td>0.14710</td>\n","      <td>...</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>842517</td>\n","      <td>M</td>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>...</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>84300903</td>\n","      <td>M</td>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>...</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>84348301</td>\n","      <td>M</td>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>...</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>84358402</td>\n","      <td>M</td>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>...</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows √ó 33 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32a4e997-2942-4d84-a907-7b2a970a34b0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-32a4e997-2942-4d84-a907-7b2a970a34b0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-32a4e997-2942-4d84-a907-7b2a970a34b0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":3}],"source":["url = \"https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv\"\n","df = pd.read_csv(url)\n","\n","print(\"Dataset Shape:\", df.shape)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"KqllHoemuInj"},"source":["## 3Ô∏è‚É£ Data Cleaning\n","\n","We inspect the dataset and remove columns that are not useful for training, specifically:\n","- `id`: Unique identifier for each sample.\n","- `Unnamed: 32`: An empty column often created during CSV reading due to trailing commas."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBcDMuUNuInk","executionInfo":{"status":"ok","timestamp":1770897882039,"user_tz":-330,"elapsed":10,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}},"outputId":"0ca33f83-8307-4844-db26-6c7446290656"},"outputs":[{"output_type":"stream","name":"stdout","text":["Shape after dropping columns: (569, 31)\n"]}],"source":["# Remove unnecessary columns\n","df.drop(columns=['id', 'Unnamed: 32'], inplace=True)\n","\n","print(\"Shape after dropping columns:\", df.shape)"]},{"cell_type":"markdown","metadata":{"id":"gR6itThjuInk"},"source":["## 4Ô∏è‚É£ Train-Test Split\n","\n","We separate the features (`X`) from the target variable (`y`).\n","- `X`: All columns except diagnosis.\n","- `y`: The diagnosis column ('M' or 'B').\n","\n","Then, we split the data into training (80%) and testing (20%) sets."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHt67wcuuInk","executionInfo":{"status":"ok","timestamp":1770897884415,"user_tz":-330,"elapsed":53,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}},"outputId":"3913488b-bda1-4114-d4ed-9ff9d7ac28c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Features Shape: (455, 30)\n","Testing Features Shape: (114, 30)\n"]}],"source":["X = df.iloc[:, 1:]      # All features (excluding diagnosis at index 0)\n","y = df.iloc[:, 0]       # diagnosis column\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.2,\n","    random_state=42\n",")\n","\n","print(\"Training Features Shape:\", X_train.shape)\n","print(\"Testing Features Shape:\", X_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"qBh2enq4uInk"},"source":["## 5Ô∏è‚É£ Feature Scaling\n","\n","Standardization calculates the mean and standard deviation for each feature and scales the data so that the mean is 0 and standard deviation is 1.\n","This is crucial for neural networks to converge faster."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrRH9ndCuInl","executionInfo":{"status":"ok","timestamp":1770897886330,"user_tz":-330,"elapsed":21,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}},"outputId":"af9912a8-8620-44d8-d0d8-1cb735251596"},"outputs":[{"output_type":"stream","name":"stdout","text":["First 3 rows of Scaled Training Data:\n"," [[-1.44075296 -0.43531947 -1.36208497 -1.1391179   0.78057331  0.71892128\n","   2.82313451 -0.11914956  1.09266219  2.45817261 -0.26380039 -0.01605246\n","  -0.47041357 -0.47476088  0.83836493  3.25102691  8.43893667  3.39198733\n","   2.62116574  2.06120787 -1.23286131 -0.47630949 -1.24792009 -0.97396758\n","   0.72289445  1.18673232  4.67282796  0.9320124   2.09724217  1.88645014]\n"," [ 1.97409619  1.73302577  2.09167167  1.85197292  1.319843    3.42627493\n","   2.01311199  2.66503199  2.1270036   1.55839569  0.80531919 -0.81268678\n","   0.75195659  0.87716951 -0.89605315  1.18122247  0.18362761  0.60059598\n","  -0.31771686  0.52963649  2.17331385  1.3112795   2.08161691  2.1374055\n","   0.76192793  3.26560084  1.92862053  2.6989469   1.89116053  2.49783848]\n"," [-1.39998202 -1.24962228 -1.34520926 -1.10978518 -1.33264483 -0.30735463\n","  -0.36555756 -0.69650228  1.93033305  0.95437877  0.02752055  1.96305996\n","  -0.12095781 -0.35077918  0.57276579  0.7394992   0.32065553  0.58946222\n","   2.61504052  0.71892779 -1.29528358 -1.04081128 -1.24522047 -0.99971493\n","  -1.43869328 -0.54856427 -0.64491059 -0.97023893  0.59760192  0.0578942 ]]\n"]}],"source":["scaler = StandardScaler()\n","\n","# Fit on training set only to avoid data leakage\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","print(\"First 3 rows of Scaled Training Data:\\n\", X_train[:3])"]},{"cell_type":"markdown","metadata":{"id":"ARcLoslAuInl"},"source":["## 6Ô∏è‚É£ Label Encoding\n","\n","The target variable has categorical values:\n","- **M** (Malignant) -> Encoded as **1**\n","- **B** (Benign) -> Encoded as **0**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZN2scOkuInl","executionInfo":{"status":"ok","timestamp":1770897888886,"user_tz":-330,"elapsed":8,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}},"outputId":"60ff8f0a-ddde-49ba-ac22-056593193e3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded Labels Example (First 10): [0 1 0 0 0 1 0 0 0 1]\n"]}],"source":["encoder = LabelEncoder()\n","\n","y_train = encoder.fit_transform(y_train)\n","y_test = encoder.transform(y_test)\n","\n","print(\"Encoded Labels Example (First 10):\", y_train[:10])"]},{"cell_type":"markdown","metadata":{"id":"nhEQ1hhluInl"},"source":["## 7Ô∏è‚É£ Convert to PyTorch Tensors\n","\n","PyTorch works with Tensors. We convert our numpy arrays to PyTorch tensors and ensure they are of type `float`.\n","We also reshape the target labels to be column vectors `(N, 1)`."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V5KICqMKuInl","executionInfo":{"status":"ok","timestamp":1770897891211,"user_tz":-330,"elapsed":73,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}},"outputId":"3b2c45e2-e25c-44e4-9d28-515e30bf4166"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train_tensor shape: torch.Size([455, 30])\n","y_train_tensor shape: torch.Size([455, 1])\n"]}],"source":["X_train_tensor = torch.from_numpy(X_train).float()\n","X_test_tensor  = torch.from_numpy(X_test).float()\n","\n","# Reshape labels to (N, 1)\n","y_train_tensor = torch.from_numpy(y_train).float().view(-1, 1)\n","y_test_tensor  = torch.from_numpy(y_test).float().view(-1, 1)\n","\n","print(\"X_train_tensor shape:\", X_train_tensor.shape)\n","print(\"y_train_tensor shape:\", y_train_tensor.shape)"]},{"cell_type":"markdown","metadata":{"id":"nnJH7XTKuInl"},"source":["## 8Ô∏è‚É£ Define Neural Network Model\n","\n","We define a simple Logistic Regression model class.\n","- **Attributes**:\n","    - `weights`: Initialized randomly.\n","    - `bias`: Initialized to zero.\n","- **Methods**:\n","    - `forward(X)`: Computes the linear combination `z = Xw + b` followed by the Sigmoid activation.\n","    - `loss_function(y_pred, y_true)`: Computes the Binary Cross Entropy loss."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"jihPKM6DuInm","executionInfo":{"status":"ok","timestamp":1770897893330,"user_tz":-330,"elapsed":10,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}}},"outputs":[],"source":["class MySimpleNN:\n","\n","    def __init__(self, X):\n","        # Initialize weights randomly\n","        # X.shape[1] is the number of features (30 in this case)\n","        self.weights = torch.randn(X.shape[1], 1, requires_grad=True)\n","\n","        # Initialize bias\n","        self.bias = torch.zeros(1, requires_grad=True)\n","\n","    def forward(self, X):\n","        # Linear transformation: z = X * w + b\n","        z = torch.matmul(X, self.weights) + self.bias\n","\n","        # Sigmoid activation for Binary Classification\n","        # output range: [0, 1]\n","        y_pred = torch.sigmoid(z)\n","\n","        return y_pred\n","\n","    def loss_function(self, y_pred, y_true):\n","        \"\"\"\n","        Binary Cross Entropy Loss (Manual implementation)\n","        Loss = - mean( y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred) )\n","        \"\"\"\n","        # Small epsilon to avoid log(0)\n","        epsilon = 1e-7\n","        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n","\n","        loss = -(\n","            y_true * torch.log(y_pred) +\n","            (1 - y_true) * torch.log(1 - y_pred)\n","        ).mean()\n","\n","        return loss"]},{"cell_type":"markdown","metadata":{"id":"qkCj212ouInm"},"source":["## 9Ô∏è‚É£ & üîü Training Loop\n","\n","We train the model over a fixed number of epochs.\n","In each epoch, we perform:\n","1. **Forward Pass**: Compute predictions.\n","2. **Loss Calculation**: Measure how far off predictions are from truth.\n","3. **Backward Pass**: Compute gradients.\n","4. **Parameter Update**: Adjust weights and bias using Gradient Descent.\n","\n","Hyperparameters:\n","- `learning_rate`: 0.1\n","- `epochs`: 25"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZG2HDxcuInm","executionInfo":{"status":"ok","timestamp":1770897896797,"user_tz":-330,"elapsed":331,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}},"outputId":"f9b64fe6-d114-4f36-8493-abed15be09b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Starting Training...\n","\n","Epoch [1/25] Loss: 1.3787\n","Epoch [2/25] Loss: 1.2878\n","Epoch [3/25] Loss: 1.2045\n","Epoch [4/25] Loss: 1.1300\n","Epoch [5/25] Loss: 1.0633\n","Epoch [6/25] Loss: 1.0035\n","Epoch [7/25] Loss: 0.9496\n","Epoch [8/25] Loss: 0.9009\n","Epoch [9/25] Loss: 0.8566\n","Epoch [10/25] Loss: 0.8162\n","Epoch [11/25] Loss: 0.7792\n","Epoch [12/25] Loss: 0.7451\n","Epoch [13/25] Loss: 0.7126\n","Epoch [14/25] Loss: 0.6810\n","Epoch [15/25] Loss: 0.6518\n","Epoch [16/25] Loss: 0.6247\n","Epoch [17/25] Loss: 0.5996\n","Epoch [18/25] Loss: 0.5763\n","Epoch [19/25] Loss: 0.5545\n","Epoch [20/25] Loss: 0.5342\n","Epoch [21/25] Loss: 0.5152\n","Epoch [22/25] Loss: 0.4974\n","Epoch [23/25] Loss: 0.4807\n","Epoch [24/25] Loss: 0.4649\n","Epoch [25/25] Loss: 0.4501\n"]}],"source":["# Hyperparameters\n","learning_rate = 0.1\n","epochs = 25\n","\n","# Create model instance\n","model = MySimpleNN(X_train_tensor)\n","\n","print(\"Starting Training...\\n\")\n","\n","for epoch in range(epochs):\n","\n","    # 1. Forward pass\n","    y_pred = model.forward(X_train_tensor)\n","\n","    # 2. Calculate loss\n","    loss = model.loss_function(y_pred, y_train_tensor)\n","\n","    # 3. Backpropagation (Calculate gradients)\n","    loss.backward()\n","\n","    # 4. Update parameters (Gradient Descent)\n","    with torch.no_grad():\n","        model.weights -= learning_rate * model.weights.grad\n","        model.bias    -= learning_rate * model.bias.grad\n","\n","        # Reset gradients for the next iteration\n","        model.weights.grad.zero_()\n","        model.bias.grad.zero_()\n","\n","    print(f\"Epoch [{epoch+1}/{epochs}] Loss: {loss.item():.4f}\")"]},{"cell_type":"markdown","metadata":{"id":"xYTsl1uguInm"},"source":["## 1Ô∏è‚É£1Ô∏è‚É£ Model Evaluation\n","\n","We evaluate the trained model on the unseen Test data.\n","- Compute predictions on `X_test_tensor`.\n","- Threshold probabilities at 0.5 to convert to binary classes (0 or 1).\n","- Compare predicted classes with true labels (`y_test_tensor`) to calculate accuracy."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUNwWBvxuInm","executionInfo":{"status":"ok","timestamp":1770897899637,"user_tz":-330,"elapsed":9,"user":{"displayName":"Ankit Kumar","userId":"11360077095189449224"}},"outputId":"42dffaa2-1a28-4db1-c19d-c42fe0dd2203"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.9123\n","Test Accuracy Score: 91.23%\n"]}],"source":["with torch.no_grad():\n","\n","    # Get probabilities for test set\n","    y_pred = model.forward(X_test_tensor)\n","\n","    # Convert probabilities to 0/1 classes\n","    y_pred_cls = (y_pred > 0.5).float()\n","\n","    # Calculate accuracy\n","    accuracy = (y_pred_cls == y_test_tensor).float().mean()\n","\n","    print(f\"Test Accuracy: {accuracy.item():.4f}\")\n","    print(f\"Test Accuracy Score: {accuracy.item() * 100:.2f}%\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}