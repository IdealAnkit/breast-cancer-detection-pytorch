<div align="center">

# ğŸ—ï¸ Breast Cancer Detection using PyTorch

### _Building Logistic Regression from Scratch with Deep Learning_

<p align="center">
  <img src="https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white" alt="PyTorch"/>
  <img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54" alt="Python"/>
  <img src="https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white" alt="Jupyter"/>
  <img src="https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white" alt="Scikit-Learn"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/pandas-%23150458.svg?style=flat-square&logo=pandas&logoColor=white" alt="Pandas"/>
  <img src="https://img.shields.io/badge/numpy-%23013243.svg?style=flat-square&logo=numpy&logoColor=white" alt="NumPy"/>
  <img src="https://img.shields.io/badge/license-MIT-green?style=flat-square" alt="License"/>
  <img src="https://img.shields.io/badge/accuracy-91.23%25-brightgreen?style=flat-square" alt="Accuracy"/>
</p>

<p align="center">
  <a href="#-features">Features</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-workflow">Workflow</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-results">Results</a> â€¢
  <a href="#-contributing">Contributing</a>
</p>

---

</div>

## ğŸŒŸ Overview

> **Empowering Medical AI Research with PyTorch**

This project implements a **Binary Classification Model** to detect Breast Cancer (Malignant vs. Benign) using a **Logistic Regression** model built **completely from scratch using PyTorch**. Unlike using pre-built libraries, this implementation provides a deep understanding of the underlying mathematics and neural network fundamentals.

<table>
<tr>
<td width="50%">

### ğŸ¯ **What Makes This Special?**

- ğŸ§® **From-Scratch Implementation** - No black boxes
- ğŸ“Š **Clean Pipeline** - Professional ML workflow
- ğŸ§  **Educational** - Learn the math behind ML
- ğŸ“ˆ **High Accuracy** - ~91% on test data

</td>
<td width="50%">

### ğŸ“‹ **Dataset Information**

- **Source**: Wisconsin Diagnostic Breast Cancer
- **Samples**: 569 instances
- **Features**: 30 numerical features
- **Classes**: Malignant (M) / Benign (B)

</td>
</tr>
</table>

---

## âœ¨ Features

<div align="center">

| Feature | Description                                                                 |
| :-----: | :-------------------------------------------------------------------------- |
|   ğŸ”¬    | **Medical AI Application** - Real-world breast cancer detection             |
|   ğŸ§ª    | **From-Scratch Neural Network** - Custom logistic regression implementation |
|   ğŸ“Š    | **Complete ML Pipeline** - Data preprocessing to model evaluation           |
|   ğŸ¯    | **High Performance** - Achieves ~91% accuracy on test data                  |
|   ğŸ“š    | **Educational** - Detailed comments and mathematical explanations           |
|   ğŸ”„    | **Reproducible** - Consistent results with proper random seeding            |

</div>

---

## ğŸ“‚ Project Structure

```
ğŸ“¦ BrestCancer/
â”œâ”€â”€ ğŸ““ Breast_Cancer_Detection_PyTorch.ipynb  # Main Jupyter Notebook
â”œâ”€â”€ ğŸ“„ FULL WORKFLOW EXPLANATION.txt      # Detailed workflow documentation
â”œâ”€â”€ ğŸ“ README.md                              # Project documentation (you're here!)
â””â”€â”€ ğŸ“‚ assets/                                # Images and diagrams
```

### **File Overview**

```mermaid
graph TD;
    A[ğŸ—ï¸ Breast Cancer Project] --> B[ğŸ““ Main Notebook];
    A --> C[ğŸ“„ Workflow Docs];
    A --> D[ğŸ“ README];
    A --> E[ğŸ“‚ Assets];
    B --> F[Training & Testing Code];
    C --> G[Step-by-Step Guide];
    D --> H[Project Documentation];
    E --> I[Visual Resources];
    style A fill:#ff69b4,stroke:#333,stroke-width:3px,color:#fff
    style B fill:#4169e1,stroke:#333,stroke-width:2px
    style C fill:#32cd32,stroke:#333,stroke-width:2px
    style D fill:#ffa500,stroke:#333,stroke-width:2px
    style E fill:#9370db,stroke:#333,stroke-width:2px
```

---

## ğŸš€ Quick Start

### Prerequisites

<div align="center">

![Python Version](https://img.shields.io/badge/python-3.7+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-1.7+-red.svg)

</div>

### ğŸ“¦ Installation

**Option 1: Install all dependencies at once**

```bash
pip install numpy pandas torch scikit-learn jupyter
```

**Option 2: Install individually**

<details>
<summary>Click to expand individual installation commands</summary>

```bash
# Core scientific computing
pip install numpy          # Array operations
pip install pandas         # Data manipulation

# Machine Learning
pip install torch          # PyTorch framework
pip install scikit-learn   # Preprocessing & metrics

# Notebook environment
pip install jupyter        # Interactive development
```

</details>

### ğŸ“‹ Dependency Table

<table align="center">
<thead>
  <tr>
    <th>Library</th>
    <th>Version</th>
    <th>Purpose</th>
    <th>Installation</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><b>NumPy</b></td>
    <td>â‰¥ 1.19</td>
    <td>Numerical computations</td>
    <td><code>pip install numpy</code></td>
  </tr>
  <tr>
    <td><b>Pandas</b></td>
    <td>â‰¥ 1.1</td>
    <td>Data handling & analysis</td>
    <td><code>pip install pandas</code></td>
  </tr>
  <tr>
    <td><b>PyTorch</b></td>
    <td>â‰¥ 1.7</td>
    <td>Deep learning framework</td>
    <td><code>pip install torch</code></td>
  </tr>
  <tr>
    <td><b>Scikit-Learn</b></td>
    <td>â‰¥ 0.23</td>
    <td>Preprocessing & metrics</td>
    <td><code>pip install scikit-learn</code></td>
  </tr>
  <tr>
    <td><b>Jupyter</b></td>
    <td>Latest</td>
    <td>Interactive notebook</td>
    <td><code>pip install jupyter</code></td>
  </tr>
</tbody>
</table>

### ğŸƒâ€â™‚ï¸ Running the Project

```bash
# Clone the repository (if applicable)
git clone <repository-url>
cd BrestCancer

# Launch Jupyter Notebook
jupyter notebook Breast_Cancer_Detection_PyTorch.ipynb

# Or use Jupyter Lab for a modern interface
jupyter lab
```

> ğŸ’¡ **Tip**: You can also run this notebook on [Google Colab](https://colab.research.google.com/) for free GPU access!

---

## ï¿½ Complete Workflow Pipeline

<div align="center">

### **End-to-End Machine Learning Pipeline**

</div>

```mermaid
graph LR;
    A[ğŸ’¾ Load Data] --> B[ğŸ§¹ Data Cleaning];
    B --> C[âœ‚ï¸ Train-Test Split];
    C --> D[âš–ï¸ Feature Scaling];
    D --> E[ğŸ”¤ Label Encoding];
    E --> F[ğŸ”¥ PyTorch Tensors];
    F --> G[ğŸ§  Model Training];
    G --> H[ğŸ“Š Evaluation];
    H --> I[ğŸ¯ Predictions];
    style A fill:#ff6b6b,stroke:#333,stroke-width:2px,color:#fff
    style B fill:#4ecdc4,stroke:#333,stroke-width:2px,color:#fff
    style C fill:#45b7d1,stroke:#333,stroke-width:2px,color:#fff
    style D fill:#96ceb4,stroke:#333,stroke-width:2px,color:#fff
    style E fill:#ffeaa7,stroke:#333,stroke-width:2px
    style F fill:#dfe6e9,stroke:#333,stroke-width:2px
    style G fill:#a29bfe,stroke:#333,stroke-width:2px,color:#fff
    style H fill:#fd79a8,stroke:#333,stroke-width:2px,color:#fff
    style I fill:#00b894,stroke:#333,stroke-width:2px,color:#fff
```

### **Detailed Pipeline Steps**

<table>
<tr>
<td width="5%">1ï¸âƒ£</td>
<td width="20%"><b>Import Libraries</b></td>
<td>Load necessary Python libraries (<code>numpy</code>, <code>pandas</code>, <code>torch</code>, <code>sklearn</code>)</td>
</tr>
<tr>
<td>2ï¸âƒ£</td>
<td><b>Load Dataset</b></td>
<td>Fetch the Breast Cancer dataset from remote URL or local storage</td>
</tr>
<tr>
<td>3ï¸âƒ£</td>
<td><b>Data Cleaning</b></td>
<td>Remove unused/irrelevant columns (<code>id</code>, <code>Unnamed: 32</code>)</td>
</tr>
<tr>
<td>4ï¸âƒ£</td>
<td><b>Train-Test Split</b></td>
<td>Divide data into training (80%) and testing (20%) sets</td>
</tr>
<tr>
<td>5ï¸âƒ£</td>
<td><b>Feature Scaling</b></td>
<td>Normalize features using <code>StandardScaler</code> for better convergence</td>
</tr>
<tr>
<td>6ï¸âƒ£</td>
<td><b>Label Encoding</b></td>
<td>Convert categorical labels (<code>M</code>, <code>B</code>) to numerical values (<code>1</code>, <code>0</code>)</td>
</tr>
<tr>
<td>7ï¸âƒ£</td>
<td><b>PyTorch Tensors</b></td>
<td>Convert NumPy arrays to PyTorch tensors for GPU acceleration</td>
</tr>
<tr>
<td>8ï¸âƒ£</td>
<td><b>Define Model</b></td>
<td>Create custom Logistic Regression neural network class</td>
</tr>
<tr>
<td>9ï¸âƒ£</td>
<td><b>Loss Function</b></td>
<td>Implement <b>Binary Cross Entropy Loss</b> manually from scratch</td>
</tr>
<tr>
<td>ğŸ”Ÿ</td>
<td><b>Training Loop</b></td>
<td>Train using Gradient Descent: Forward â†’ Loss â†’ Backward â†’ Update</td>
</tr>
<tr>
<td>1ï¸âƒ£1ï¸âƒ£</td>
<td><b>Evaluation</b></td>
<td>Test model accuracy on unseen test data and compute metrics</td>
</tr>
</table>

<div align="center">

### **Training Process Visualization**

```mermaid
sequenceDiagram
    participant Data as ğŸ“Š Training Data
    participant Model as ğŸ§  Neural Network
    participant Loss as ğŸ“‰ Loss Function
    participant Optimizer as âš™ï¸ Gradient Descent

    loop Each Epoch (25 iterations)
        Data->>Model: Forward Pass (Input â†’ Output)
        Model->>Loss: Calculate Binary Cross Entropy
        Loss->>Optimizer: Compute Gradients (âˆ‚L/âˆ‚w)
        Optimizer->>Model: Update Weights (w = w - Î±âˆ‡w)
        Note over Model: Repeat until convergence
    end
    Model->>Data: Final Trained Model ğŸ¯
```

</div>

---

## ğŸ§  Neural Network Architecture & Logic

<div align="center">

### **From-Scratch Logistic Regression Model**

</div>

We define a custom neural network model called `MySimpleNN` that implements Logistic Regression using only PyTorch tensors and operations.

### ğŸ—ï¸ Architecture Diagram

```mermaid
graph TD;
    Input[ğŸ“¥ Input Features<br/>30 numerical features] -->|Matrix Multiplication| Linear[âš™ï¸ Linear Transformation<br/>z = Xw + b];
    Linear -->|Activation Function| Activation[ğŸ”„ Sigmoid Function<br/>Output between 0 and 1];
    Activation -->|Probability| Prob[ğŸ“Š Probability Output<br/>Range: 0 to 1];
    Prob -->|Decision Boundary| Output[ğŸ¯ Binary Classification<br/>Threshold: 0.5<br/>Class: 0 or 1];

    style Input fill:#e3f2fd,stroke:#1976d2,stroke-width:3px
    style Linear fill:#fff3e0,stroke:#f57c00,stroke-width:3px
    style Activation fill:#f3e5f5,stroke:#7b1fa2,stroke-width:3px
    style Prob fill:#e8f5e9,stroke:#388e3c,stroke-width:3px
    style Output fill:#ffebee,stroke:#c62828,stroke-width:3px
```

### ğŸ“ Mathematical Foundation

<div align="center">

|        Component         |                            Formula                            | Description               |
| :----------------------: | :-----------------------------------------------------------: | :------------------------ |
|  **Linear Combination**  |                         $z = Xw + b$                          | Weighted sum of inputs    |
|  **Sigmoid Activation**  |              $\sigma(z) = \frac{1}{1 + e^{-z}}$               | Maps to probability [0,1] |
| **Binary Cross Entropy** | $L = -\frac{1}{n}\sum[y\log(\hat{y}) + (1-y)\log(1-\hat{y})]$ | Loss function             |
|   **Gradient Descent**   |        $w = w - \alpha \frac{\partial L}{\partial w}$         | Weight update rule        |

</div>

### ğŸ”§ Key Components

<table>
<tr>
<td width="30%"><b>ğŸ² Weights (w)</b></td>
<td>Randomly initialized tensor of shape <code>(30, 1)</code> with <code>requires_grad=True</code></td>
</tr>
<tr>
<td><b>ğŸ“ Bias (b)</b></td>
<td>Zero-initialized tensor for offset adjustment</td>
</tr>
<tr>
<td><b>â¡ï¸ Forward Pass</b></td>
<td>Computes <code>z = Xw + b</code> followed by <code>Sigmoid(z)</code> activation</td>
</tr>
<tr>
<td><b>ğŸ“‰ Loss Function</b></td>
<td>Custom Binary Cross Entropy implementation (not using PyTorch's built-in)</td>
</tr>
<tr>
<td><b>ğŸ”™ Backpropagation</b></td>
<td>Automatic differentiation via PyTorch's autograd engine</td>
</tr>
<tr>
<td><b>âš¡ Optimizer</b></td>
<td>Manual Gradient Descent implementation with learning rate Î±=0.1</td>
</tr>
</table>

### ğŸ’» Code Implementation

<details>
<summary><b>Click to expand: Model Class Implementation</b></summary>

```python
class MySimpleNN:
    """
    Custom Logistic Regression Neural Network
    Built from scratch using PyTorch tensors
    """
    def __init__(self, X):
        # Initialize weights randomly from normal distribution
        self.weights = torch.randn(X.shape[1], 1, requires_grad=True)

        # Initialize bias to zero
        self.bias = torch.zeros(1, requires_grad=True)

    def forward(self, X):
        """
        Forward propagation through the network

        Args:
            X: Input features tensor

        Returns:
            Sigmoid activated output (probabilities)
        """
        # Linear transformation: z = Xw + b
        z = torch.matmul(X, self.weights) + self.bias

        # Apply sigmoid activation: Ïƒ(z) = 1/(1+e^(-z))
        return torch.sigmoid(z)
```

</details>

<details>
<summary><b>Click to expand: Loss Function Implementation</b></summary>

```python
def binary_cross_entropy_loss(y_pred, y_true):
    """
    Custom Binary Cross Entropy Loss

    Formula: L = -1/n * Î£[y*log(Å·) + (1-y)*log(1-Å·)]

    Args:
        y_pred: Predicted probabilities
        y_true: True labels (0 or 1)

    Returns:
        Average loss across all samples
    """
    epsilon = 1e-7  # Small constant to avoid log(0)

    # Clip predictions to prevent log(0)
    y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)

    # Calculate BCE loss
    loss = -torch.mean(
        y_true * torch.log(y_pred) +
        (1 - y_true) * torch.log(1 - y_pred)
    )

    return loss
```

</details>

### ğŸ¯ Model Architecture Summary

```mermaid
graph LR
    A[Input Layer<br/>30 features] -->|Weights 30x1<br/>+Bias 1x1| B[Linear Layer<br/>z = Xw + b]
    B -->|Sigmoid Ïƒ| C[Output Layer<br/>Probability]
    C -->|Threshold > 0.5| D[Class: 0 or 1]

    style A fill:#3498db,color:#fff
    style B fill:#e74c3c,color:#fff
    style C fill:#2ecc71,color:#fff
    style D fill:#f39c12,color:#fff
```

---

## ğŸ“Š Results and Performance

<div align="center">

### **Model Performance Metrics**

<table>
<thead>
  <tr>
    <th>Metric</th>
    <th>Value</th>
    <th>Visualization</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td><b>ğŸ¯ Accuracy</b></td>
    <td><h3>91.23%</h3></td>
    <td>
      <img src="https://progress-bar.dev/91/?title=Test%20Accuracy&width=200&color=00d154" alt="Accuracy"/>
    </td>
  </tr>
  <tr>
    <td><b>ğŸ“ˆ Epochs</b></td>
    <td>25</td>
    <td>â±ï¸ Quick convergence</td>
  </tr>
  <tr>
    <td><b>âš¡ Learning Rate</b></td>
    <td>0.1</td>
    <td>ğŸšï¸ Optimal for this dataset</td>
  </tr>
  <tr>
    <td><b>ğŸ”¢ Parameters</b></td>
    <td>31 (30 weights + 1 bias)</td>
    <td>ğŸ’¾ Lightweight model</td>
  </tr>
</tbody>
</table>

</div>

### ğŸ“‰ Training Progression

```mermaid
graph LR
    E1[Epoch 1<br/>Loss: High] --> E5[Epoch 5<br/>Loss â†“]
    E5 --> E10[Epoch 10<br/>Loss â†“â†“]
    E10 --> E15[Epoch 15<br/>Loss â†“â†“â†“]
    E15 --> E20[Epoch 20<br/>Loss â†“â†“â†“â†“]
    E20 --> E25[Epoch 25<br/>Converged âœ“]

    style E1 fill:#ff6b6b,color:#fff
    style E5 fill:#ffa07a,color:#fff
    style E10 fill:#ffd700
    style E15 fill:#90ee90
    style E20 fill:#00d154,color:#fff
    style E25 fill:#2ecc71,color:#fff
```

### ğŸ¨ Performance Highlights

<table>
<tr>
<td width="50%">

#### âœ… **Strengths**

- ğŸ¯ High accuracy on test data
- âš¡ Fast training convergence
- ğŸ“‰ Low computational cost
- ğŸ§® Simple, interpretable model
- ğŸ’¡ Easy to understand and debug

</td>
<td width="50%">

#### ğŸ”„ **Potential Improvements**

- ğŸ”¬ Add more evaluation metrics
- ğŸ“Š Implement confusion matrix
- ğŸšï¸ Try different learning rates
- ğŸ” Add early stopping
- ğŸ§ª K-fold cross-validation

</td>
</tr>
</table>

### ğŸ’» Evaluation Code

```python
# Make predictions on test set
with torch.no_grad():
    y_pred = model.forward(X_test_tensor)
    y_pred_cls = (y_pred >= 0.5).float()

# Calculate accuracy
accuracy = (y_pred_cls == y_test_tensor).float().mean()
print(f"Test Accuracy Score: {accuracy.item() * 100:.2f}%")
```

### ğŸ“Œ Important Notes

> âš ï¸ **Note**: Accuracy may vary slightly (Â±1-2%) due to:
>
> - Random initialization of weights
> - Stochastic nature of gradient descent
> - Train-test split randomness
>
> ğŸ’¡ **Tip**: Use `torch.manual_seed()` for reproducible results!

<div align="center">

### **Confusion Matrix (Conceptual)**

|                       | Predicted: Benign | Predicted: Malignant |
| :-------------------: | :---------------: | :------------------: |
|  **Actual: Benign**   | âœ… True Negative  |  âŒ False Positive   |
| **Actual: Malignant** | âŒ False Negative |   âœ… True Positive   |

</div>

---

## ğŸ® Usage Guide

### **Step 1: Clone & Navigate**

```bash
# Clone the repository (if applicable)
git clone <repository-url>
cd BrestCancer
```

### **Step 2: Set Up Environment**

```bash
# Install dependencies
pip install -r requirements.txt

# Or install manually
pip install numpy pandas torch scikit-learn jupyter
```

### **Step 3: Launch Notebook**

<table>
<tr>
<td width="50%">

#### **Option A: Jupyter Notebook**

```bash
jupyter notebook Breast_Cancer_Detection_PyTorch.ipynb
```

Traditional notebook interface

</td>
<td width="50%">

#### **Option B: Jupyter Lab**

```bash
jupyter lab
```

Modern, feature-rich interface

</td>
</tr>
<tr>
<td>

#### **Option C: VS Code**

```bash
code .
```

Use VS Code notebook support

</td>
<td>

#### **Option D: Google Colab**

```
Upload notebook to Colab
```

Free GPU/TPU access â˜ï¸

</td>
</tr>
</table>

### **Step 4: Run All Cells**

1. ğŸ”„ Execute cells sequentially from top to bottom
2. ğŸ“Š Watch the training progress
3. ğŸ¯ View the final accuracy results

### ğŸ¯ Quick Example

```python
# Quick test prediction example
import torch

# Sample feature values (30 features)
sample_data = torch.randn(1, 30)

# Make prediction
with torch.no_grad():
    prediction = model.forward(sample_data)
    class_label = "Malignant" if prediction >= 0.5 else "Benign"

print(f"Prediction: {class_label} (Confidence: {prediction.item():.2%})")
```

---

## ğŸ¤ Contributing

<div align="center">

**We welcome contributions!** ğŸ‰

</div>

### How to Contribute

<table>
<tr>
<td>1ï¸âƒ£</td>
<td><b>Fork the Project</b></td>
<td>Create your own copy of the repository</td>
</tr>
<tr>
<td>2ï¸âƒ£</td>
<td><b>Create a Branch</b></td>
<td><code>git checkout -b feature/AmazingFeature</code></td>
</tr>
<tr>
<td>3ï¸âƒ£</td>
<td><b>Commit Changes</b></td>
<td><code>git commit -m 'Add some AmazingFeature'</code></td>
</tr>
<tr>
<td>4ï¸âƒ£</td>
<td><b>Push to Branch</b></td>
<td><code>git push origin feature/AmazingFeature</code></td>
</tr>
<tr>
<td>5ï¸âƒ£</td>
<td><b>Open Pull Request</b></td>
<td>Submit your changes for review</td>
</tr>
</table>

### ğŸ’¡ Contribution Ideas

- ğŸ“Š Add visualization of training loss
- ğŸ”¬ Implement additional metrics (precision, recall, F1)
- ğŸ¨ Create confusion matrix visualization
- ğŸ“ˆ Add learning rate scheduling
- ğŸ§ª Implement cross-validation
- ğŸ“ Improve documentation
- ğŸ› Report bugs or issues

---

## â“ FAQ (Frequently Asked Questions)

<details>
<summary><b>Q: Why build from scratch instead of using sklearn's LogisticRegression?</b></summary>

**A:** This project is educational! Building from scratch helps you understand:

- The mathematics behind logistic regression
- How neural networks actually work
- PyTorch's autograd mechanism
- Gradient descent optimization process

</details>

<details>
<summary><b>Q: Can I use this for other binary classification tasks?</b></summary>

**A:** Absolutely! Just replace the dataset loading part with your own data. The model architecture works for any binary classification problem.

</details>

<details>
<summary><b>Q: Why is my accuracy different from 91.23%?</b></summary>

**A:** Slight variations (Â±1-2%) are normal due to:

- Random weight initialization
- Random train-test split
- Floating-point precision

Use `torch.manual_seed(42)` for reproducibility!

</details>

<details>
<summary><b>Q: Can I use GPU for faster training?</b></summary>

**A:** Yes! Add this code before training:

```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
X_train_tensor = X_train_tensor.to(device)
model.weights = model.weights.to(device)
# ... move other tensors to device
```

</details>

<details>
<summary><b>Q: How can I save the trained model?</b></summary>

**A:** Save the weights and bias:

```python
torch.save({
    'weights': model.weights,
    'bias': model.bias
}, 'breast_cancer_model.pth')
```

</details>

<details>
<summary><b>Q: What's the difference between this and deep learning?</b></summary>

**A:** This is a single-layer neural network (logistic regression). Deep learning uses multiple layers. This project teaches the fundamentals that scale to deeper networks!

</details>

---

## ğŸ“š Dataset Information

### **Breast Cancer Wisconsin (Diagnostic) Dataset**

<table>
<tr>
<td width="30%"><b>ğŸ“Š Total Samples</b></td>
<td>569 instances</td>
</tr>
<tr>
<td><b>ğŸ“ˆ Features</b></td>
<td>30 numerical features (computed from cell nuclei images)</td>
</tr>
<tr>
<td><b>ğŸ¯ Classes</b></td>
<td>
  <ul>
    <li><b>Malignant (M)</b>: 212 samples (37.3%)</li>
    <li><b>Benign (B)</b>: 357 samples (62.7%)</li>
  </ul>
</td>
</tr>
<tr>
<td><b>ğŸ”¬ Feature Types</b></td>
<td>Radius, Texture, Perimeter, Area, Smoothness, Compactness, Concavity, Concave Points, Symmetry, Fractal Dimension (each with mean, SE, and worst values)</td>
</tr>
<tr>
<td><b>ğŸ“ Source</b></td>
<td>UCI Machine Learning Repository / sklearn.datasets</td>
</tr>
<tr>
<td><b>ğŸ“… Created</b></td>
<td>Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian</td>
</tr>
</table>

### ğŸ” Feature Engineering

The 30 features are organized into 3 groups of 10:

- **Mean values** (features 1-10)
- **Standard error** (features 11-20)
- **Worst/largest** (features 21-30)

Each group contains measurements for: radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, and fractal dimension.

---

## ğŸ“– Learning Resources

<div align="center">

### **Expand Your Knowledge**

</div>

| Topic                      | Resources                                                                                                           |
| :------------------------- | :------------------------------------------------------------------------------------------------------------------ |
| ğŸ§® **Linear Algebra**      | [3Blue1Brown - Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) |
| ğŸ§  **Neural Networks**     | [3Blue1Brown - Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)           |
| ğŸ”¥ **PyTorch**             | [Official PyTorch Tutorials](https://pytorch.org/tutorials/)                                                        |
| ğŸ“Š **Machine Learning**    | [Andrew Ng's ML Course](https://www.coursera.org/learn/machine-learning)                                            |
| ğŸ“ˆ **Logistic Regression** | [StatQuest: Logistic Regression](https://www.youtube.com/watch?v=yIYKR4sgzI8)                                       |

---

## ğŸ“œ License

<div align="center">

This project is licensed under the **MIT License**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

See the [LICENSE](LICENSE) file for details.

</div>

---

## ğŸ™ Acknowledgements

<div align="center">

**Special Thanks To:**

</div>

- ğŸ©º **Dr. William H. Wolberg** - for creating the Breast Cancer Wisconsin dataset
- ğŸ”¥ **PyTorch Team** - for the amazing deep learning framework
- ğŸ“Š **Scikit-Learn Contributors** - for excellent ML utilities
- ğŸ“ **Open Source Community** - for continuous support and inspiration
- ğŸ’– **Medical AI Researchers** - for advancing healthcare through technology

---

## ğŸ“ Contact & Support

<div align="center">

### **Get in Touch**

<table>
<tr>
<td align="center">
<b>ğŸ› Found a Bug?</b><br>
<a href="https://github.com/yourusername/BrestCancer/issues">Report Issue</a>
</td>
<td align="center">
<b>ğŸ’¡ Have an Idea?</b><br>
<a href="https://github.com/yourusername/BrestCancer/issues">Request Feature</a>
</td>
<td align="center">
<b>â“ Need Help?</b><br>
<a href="https://github.com/yourusername/BrestCancer/discussions">Join Discussion</a>
</td>
</tr>
</table>

---

### **Show Your Support**

If you found this project helpful, please consider:

â­ **Star** this repository  
ğŸ”€ **Fork** and contribute  
ğŸ“¢ **Share** with others  
ğŸ’¬ **Provide feedback**

---

<img src="https://img.shields.io/github/stars/yourusername/BrestCancer?style=social" alt="Stars"/>
<img src="https://img.shields.io/github/forks/yourusername/BrestCancer?style=social" alt="Forks"/>
<img src="https://img.shields.io/github/watchers/yourusername/BrestCancer?style=social" alt="Watchers"/>

</div>

---

## ğŸ† Project Stats

<div align="center">

![Lines of Code](https://img.shields.io/badge/Lines%20of%20Code-500+-blue)
![Code Quality](https://img.shields.io/badge/Code%20Quality-A-brightgreen)
![Documentation](https://img.shields.io/badge/Documentation-Excellent-green)
![Maintained](https://img.shields.io/badge/Maintained-Yes-success)

</div>

---

<div align="center">

### **Made with â¤ï¸ for Medical AI Research**

_Empowering Healthcare through Machine Learning_

---

## ğŸ“ Project Credits

<table align="center">
<tr>
<td align="center">
<img src="https://avatars.githubusercontent.com/u/155890684?v=4" width="60"/>
<br><b>ğŸ‘¨â€ğŸ’» Development</b>
<br><sub>SEM 7 Student Project</sub>
<br><sub>PyTorch Implementation</sub>
</td>
<td align="center">
<img src="https://raw.githubusercontent.com/pytorch/pytorch/master/docs/source/_static/img/pytorch-logo-dark.png" width="80"/>
<br><b>ğŸ”¥ AI Framework</b>
<br><sub>PyTorch</sub>
<br><sub>Deep Learning Library</sub>
</td>
<td align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg" width="70"/>
<br><b>ğŸ§ª ML Library</b>
<br><sub>Scikit-Learn</sub>
<br><sub>Data Preprocessing</sub>
</td>
</tr>
<tr>
<td align="center">
<img src="https://img.icons8.com/fluency/96/000000/source-code.png" width="60"/>
<br><b>ğŸ› ï¸ Open Source Tools</b>
<br><sub>NumPy, Pandas</sub>
<br><sub>Python Ecosystem</sub>
</td>
<td align="center">
<img src="https://img.icons8.com/color/96/000000/medical-heart.png" width="60"/>
<br><b>ğŸ©º Medical Dataset</b>
<br><sub>Wisconsin Breast Cancer</sub>
<br><sub>UCI ML Repository</sub>
</td>
<td align="center">
<img src="https://img.icons8.com/fluency/96/000000/jupyter.png" width="60"/>
<br><b>ğŸ““ Environment</b>
<br><sub>Jupyter Notebook</sub>
<br><sub>Interactive Computing</sub>
</td>
</tr>
</table>

---

**Â© 2026 Breast Cancer Detection Project**

<sub>This project is for educational purposes. Not intended for clinical diagnosis.</sub>

---

<p>
  <a href="#-overview">Back to Top â†‘</a>
</p>

</div>
